Insider Threat Detection

Team Name: Quatrix
Team Member: Divya Pugalendiran, Hemila Saravanan, Bodhana A, and Lokireddy Madhavi

ğŸ“Œ Overview

This project detects insider threats by analyzing three core activity logs. Machine-learning models flag suspicious patterns such as unusual logins, unexpected file access, and abnormal application usage to help prevent internal security breaches.

ğŸš€ Features

Three-Source Data Integration: Merges

login.csv â€“ user login/logout events

file_access.csv â€“ file access records

application_usage.csv â€“ application start/end logs

GRU Autoencoder: Unsupervised anomaly detection.

Federated Learning (FedAvg): Simulated privacy-preserving training across nodes.

Random Forest Detector: Final supervised classification and validation.

ğŸ—ï¸ Tech Stack

Language: Python

Libraries: Pandas, NumPy, Scikit-learn, TensorFlow/PyTorch, Matplotlib

Environment: Google Colab (all notebooks and scripts can be run end-to-end in Colabâ€”no local setup required)

âš™ï¸ Methodology

Preprocessing â€“ Cleaned, normalized, and engineered features from the three datasets.

Modeling â€“

GRU Autoencoder for anomaly detection

Federated Learning (FedAvg) for distributed privacy

Random Forest for supervised threat detection

Evaluation â€“ Accuracy, confusion matrix, and classification metrics.

ğŸ“Š Results

High detection accuracy with minimal false positives.

Federated learning performed on par with centralized training while preserving privacy.
